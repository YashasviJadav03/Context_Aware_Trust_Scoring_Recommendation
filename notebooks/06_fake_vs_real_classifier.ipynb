{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Fake vs Real Classifier\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 1. Import Required Libraries"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [],
            "source": [
                "\n",
                "import pandas as pd\n",
                "import numpy as np\n",
                "\n",
                "from sklearn.model_selection import train_test_split\n",
                "from sklearn.feature_extraction.text import TfidfVectorizer\n",
                "from sklearn.linear_model import LogisticRegression\n",
                "from sklearn.preprocessing import StandardScaler\n",
                "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
                "from scipy.sparse import hstack\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 2. Load Weakly Labeled Dataset"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Loading dataset...\n",
                        "Dataset shape: (882403, 21)\n",
                        "\n",
                        "Columns: ['user_id', 'product_id', 'rating', 'review_text', 'summary', 'verified', 'review_timestamp', 'clean_review_text', 'review_date', 'review_length', 'rule_short_extreme', 'review_day', 'daily_count', 'rule_high_frequency', 'product_mean_rating', 'rating_deviation', 'rule_rating_deviation', 'rule_duplicate', 'fake_score', 'fake_label', 'label_confidence']\n",
                        "          user_id  product_id  rating  \\\n",
                        "0  A1D4G1SNUZWQOT  7106116521       5   \n",
                        "1  A3DDWDH9PX2YX2  7106116521       2   \n",
                        "2  A2MWC41EW7XL15  7106116521       4   \n",
                        "3  A2UH2QQ275NV45  7106116521       2   \n",
                        "4   A89F3LQADZBS5  7106116521       3   \n",
                        "\n",
                        "                                         review_text  \\\n",
                        "0                             exactly what i needed.   \n",
                        "1  i agree with the other review, the opening is ...   \n",
                        "2  love these... i am going to order another pack...   \n",
                        "3                                too tiny an opening   \n",
                        "4                                               okay   \n",
                        "\n",
                        "                                             summary  verified  \\\n",
                        "0                             perfect replacements!!      True   \n",
                        "1  I agree with the other review, the opening is ...      True   \n",
                        "2                                My New 'Friends' !!     False   \n",
                        "3                                          Two Stars      True   \n",
                        "4                                        Three Stars     False   \n",
                        "\n",
                        "   review_timestamp                                  clean_review_text  \\\n",
                        "0        1413763200                             exactly what i needed.   \n",
                        "1        1411862400  i agree with the other review, the opening is ...   \n",
                        "2        1408924800  love these... i am going to order another pack...   \n",
                        "3        1408838400                                too tiny an opening   \n",
                        "4        1406419200                                               okay   \n",
                        "\n",
                        "  review_date  review_length  ...  review_day daily_count  \\\n",
                        "0  2014-10-20              4  ...  2014-10-20           1   \n",
                        "1  2014-09-28             46  ...  2014-09-28           1   \n",
                        "2  2014-08-25             45  ...  2014-08-25           1   \n",
                        "3  2014-08-24              4  ...  2014-08-24           1   \n",
                        "4  2014-07-27              1  ...  2014-07-27           1   \n",
                        "\n",
                        "   rule_high_frequency  product_mean_rating  rating_deviation  \\\n",
                        "0                    0             3.823529          1.176471   \n",
                        "1                    0             3.823529          1.823529   \n",
                        "2                    0             3.823529          0.176471   \n",
                        "3                    0             3.823529          1.823529   \n",
                        "4                    0             3.823529          0.823529   \n",
                        "\n",
                        "   rule_rating_deviation  rule_duplicate  fake_score  fake_label  \\\n",
                        "0                      0               1           3           1   \n",
                        "1                      0               0           0           0   \n",
                        "2                      0               0           0           0   \n",
                        "3                      0               0           0           0   \n",
                        "4                      0               1           2           1   \n",
                        "\n",
                        "   label_confidence  \n",
                        "0         high_fake  \n",
                        "1         high_real  \n",
                        "2         high_real  \n",
                        "3         high_real  \n",
                        "4         uncertain  \n",
                        "\n",
                        "[5 rows x 21 columns]\n"
                    ]
                }
            ],
            "source": [
                "print(\"Loading dataset...\")\n",
                "df = pd.read_csv(\"../data/processed/labeled_reviews.csv\")\n",
                "\n",
                "print(f\"Dataset shape: {df.shape}\")\n",
                "print(f\"\\nColumns: {df.columns.tolist()}\")\n",
                "print(df.head())"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 3. Select Required Features"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 16,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Preparing features...\n",
                        "Text features: 882403 samples\n",
                        "Numeric features shape: (882403, 2)\n",
                        "Target distribution:\n",
                        "fake_label\n",
                        "0    723325\n",
                        "1    159078\n",
                        "Name: count, dtype: int64\n"
                    ]
                }
            ],
            "source": [
                "\n",
                "# Select Required Features\n",
                "print(\"Preparing features...\")\n",
                "\n",
                "# Text Feature\n",
                "X_text = df[\"review_text\"].astype(str)\n",
                "\n",
                "# Numerical Features\n",
                "X_numeric = df[[\"review_length\", \"rating_deviation\"]]\n",
                "\n",
                "# Target\n",
                "y = df[\"fake_label\"]\n",
                "\n",
                "print(f\"Text features: {len(X_text)} samples\")\n",
                "print(f\"Numeric features shape: {X_numeric.shape}\")\n",
                "print(f\"Target distribution:\\n{y.value_counts()}\")\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 4. Train-Test Split\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 17,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Splitting data...\n",
                        "Training samples: 705922\n",
                        "Test samples: 176481\n",
                        "\n",
                        "Train label distribution:\n",
                        "fake_label\n",
                        "0    0.819722\n",
                        "1    0.180278\n",
                        "Name: proportion, dtype: float64\n"
                    ]
                }
            ],
            "source": [
                "print(\"Splitting data...\")\n",
                "\n",
                "X_text_train, X_text_test, X_num_train, X_num_test, y_train, y_test = train_test_split(\n",
                "    X_text,\n",
                "    X_numeric,\n",
                "    y,\n",
                "    test_size=0.2,\n",
                "    random_state=42,\n",
                "    stratify=y\n",
                ")\n",
                "\n",
                "print(f\"Training samples: {len(y_train)}\")\n",
                "print(f\"Test samples: {len(y_test)}\")\n",
                "print(f\"\\nTrain label distribution:\\n{y_train.value_counts(normalize=True)}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 5. TF-IDF Vectorization\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Creating TF-IDF features...\n",
                        "TF-IDF train shape: (705922, 5000)\n",
                        "TF-IDF test shape: (176481, 5000)\n"
                    ]
                }
            ],
            "source": [
                "print(\"Creating TF-IDF features...\")\n",
                "\n",
                "tfidf = TfidfVectorizer(\n",
                "    stop_words=\"english\",\n",
                "    max_features=5000,\n",
                "    ngram_range=(1, 2)\n",
                ")\n",
                "\n",
                "X_tfidf_train = tfidf.fit_transform(X_text_train)\n",
                "X_tfidf_test = tfidf.transform(X_text_test)\n",
                "\n",
                "print(f\"TF-IDF train shape: {X_tfidf_train.shape}\")\n",
                "print(f\"TF-IDF test shape: {X_tfidf_test.shape}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "id": "c35d08e5",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Scaling numeric features...\n",
                        "Numeric features scaled.\n",
                        "Train mean: [-1.72572256e-17  6.38663296e-16]\n",
                        "Train std: [1. 1.]\n"
                    ]
                }
            ],
            "source": [
                "# Scale Numeric Features \n",
                "print(\"Scaling numeric features...\")\n",
                "\n",
                "scaler = StandardScaler()\n",
                "X_num_train_scaled = scaler.fit_transform(X_num_train)\n",
                "X_num_test_scaled = scaler.transform(X_num_test)\n",
                "\n",
                "print(f\"Numeric features scaled.\")\n",
                "print(f\"Train mean: {X_num_train_scaled.mean(axis=0)}\")\n",
                "print(f\"Train std: {X_num_train_scaled.std(axis=0)}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 6. Combine Text + Numeric Features\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 9,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Combining features...\n",
                        "Combined train features shape: (705922, 5002)\n",
                        "Combined test features shape: (176481, 5002)\n"
                    ]
                }
            ],
            "source": [
                "print(\"Combining features...\")\n",
                "\n",
                "X_train = hstack([X_tfidf_train, X_num_train_scaled])\n",
                "X_test = hstack([X_tfidf_test, X_num_test_scaled])\n",
                "\n",
                "print(f\"Combined train features shape: {X_train.shape}\")\n",
                "print(f\"Combined test features shape: {X_test.shape}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 7. Train Logistic Regression Model\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 10,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Training model...\n",
                        "Model training complete.\n"
                    ]
                }
            ],
            "source": [
                "print(\"Training model...\")\n",
                "\n",
                "model = LogisticRegression(\n",
                "    max_iter=2000,  # Increased from 1000\n",
                "    class_weight=\"balanced\",\n",
                "    random_state=42\n",
                ")\n",
                "\n",
                "model.fit(X_train, y_train)\n",
                "\n",
                "print(\"Model training complete.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 8. Make Predictions"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 11,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Making predictions...\n",
                        "Predictions made: 176481\n"
                    ]
                }
            ],
            "source": [
                "print(\"Making predictions...\")\n",
                "\n",
                "y_pred = model.predict(X_test)\n",
                "\n",
                "print(f\"Predictions made: {len(y_pred)}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 9. Evaluation Metrics\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 12,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "EVALUATION METRICS\n",
                        "Accuracy:  0.8110\n",
                        "Precision: 0.4856\n",
                        "Recall:    0.8166\n",
                        "F1-Score:  0.6090\n"
                    ]
                }
            ],
            "source": [
                "print(\"EVALUATION METRICS\")\n",
                "\n",
                "# Calculate metrics\n",
                "accuracy = accuracy_score(y_test, y_pred)\n",
                "precision = precision_score(y_test, y_pred)\n",
                "recall = recall_score(y_test, y_pred)\n",
                "f1 = f1_score(y_test, y_pred)\n",
                "\n",
                "print(f\"Accuracy:  {accuracy:.4f}\")\n",
                "print(f\"Precision: {precision:.4f}\")\n",
                "print(f\"Recall:    {recall:.4f}\")\n",
                "print(f\"F1-Score:  {f1:.4f}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 10. Confusion Matrix\n",
                "\n",
                "**Interpretation:**\n",
                "- **TP (True Positive):** Correctly detected fake\n",
                "- **FP (False Positive):** Genuine marked as fake\n",
                "- **FN (False Negative):** Missed fake\n",
                "- **TN (True Negative):** Correctly identified as real"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 13,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "CONFUSION MATRIX\n",
                        "Confusion Matrix:\n",
                        "[[117142  27523]\n",
                        " [  5836  25980]]\n",
                        "\n",
                        "[[TN  FP]\n",
                        " [FN  TP]]\n"
                    ]
                }
            ],
            "source": [
                "print(\"CONFUSION MATRIX\")\n",
                "\n",
                "cm = confusion_matrix(y_test, y_pred)\n",
                "\n",
                "print(\"Confusion Matrix:\")\n",
                "print(cm)\n",
                "print(\"\\n[[TN  FP]\")\n",
                "print(\" [FN  TP]]\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "21d24fd3",
            "metadata": {},
            "source": [
                "### 11. Summary\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 15,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "BASELINE CLASSIFIER PERFORMANCE SUMMARY\n",
                        "Accuracy:  0.8110\n",
                        "Precision: 0.4856\n",
                        "Recall:    0.8166\n",
                        "F1-Score:  0.6090\n"
                    ]
                }
            ],
            "source": [
                "print(\"BASELINE CLASSIFIER PERFORMANCE SUMMARY\")\n",
                "print(f\"Accuracy:  {accuracy:.4f}\")\n",
                "print(f\"Precision: {precision:.4f}\")\n",
                "print(f\"Recall:    {recall:.4f}\")\n",
                "print(f\"F1-Score:  {f1:.4f}\")\n"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "venv",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.11"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}
