{
    "cells": [
        {
            "cell_type": "markdown",
            "id": "996d7c35",
            "metadata": {},
            "source": [
                "# Fake vs Real Review Classifier - Complete Model Comparison"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "870183e3",
            "metadata": {},
            "source": [
                "## 1. Import Required Libraries"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "id": "b5d4b9cb",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        " Libraries imported successfully\n"
                    ]
                }
            ],
            "source": [
                "import pandas as pd\n",
                "import numpy as np\n",
                "import warnings\n",
                "warnings.filterwarnings('ignore')\n",
                "\n",
                "from sklearn.model_selection import train_test_split\n",
                "from sklearn.feature_extraction.text import TfidfVectorizer\n",
                "from sklearn.preprocessing import StandardScaler\n",
                "from sklearn.linear_model import LogisticRegression\n",
                "from sklearn.svm import LinearSVC\n",
                "from sklearn.tree import DecisionTreeClassifier\n",
                "from sklearn.ensemble import RandomForestClassifier\n",
                "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report\n",
                "from scipy.sparse import hstack\n",
                "\n",
                "# XGBoost (install with: pip install xgboost)\n",
                "try:\n",
                "    from xgboost import XGBClassifier\n",
                "    XGBOOST_AVAILABLE = True\n",
                "except ImportError:\n",
                "    print(\"WARNING:  XGBoost not installed. Run: pip install xgboost\")\n",
                "    XGBOOST_AVAILABLE = False\n",
                "from scipy.special import expit\n",
                "\n",
                "print(\" Libraries imported successfully\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "bbd0c437",
            "metadata": {},
            "source": [
                "## 2. Load and Filter Dataset"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "id": "629f744e",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Loading dataset...\n",
                        "Original dataset shape: (882403, 21)\n",
                        "\n",
                        "Label distribution:\n",
                        "fake_label\n",
                        "0    723325\n",
                        "1    159078\n",
                        "Name: count, dtype: int64\n",
                        "\n",
                        "Confidence distribution:\n",
                        "label_confidence\n",
                        "high_real    528623\n",
                        "uncertain    252974\n",
                        "high_fake    100806\n",
                        "Name: count, dtype: int64\n"
                    ]
                }
            ],
            "source": [
                "print(\"Loading dataset...\")\n",
                "df = pd.read_csv(\"../data/processed/labeled_reviews.csv\")\n",
                "\n",
                "print(f\"Original dataset shape: {df.shape}\")\n",
                "print(f\"\\nLabel distribution:\")\n",
                "print(df['fake_label'].value_counts())\n",
                "print(f\"\\nConfidence distribution:\")\n",
                "print(df['label_confidence'].value_counts())"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "bcb7bd98",
            "metadata": {},
            "source": [
                "### 2.1 Filter to High Confidence Samples"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "id": "dcc424ac",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Filtering to high confidence samples...\n",
                        "Filtered dataset size: 629429\n",
                        "Removed: 252974 samples (28.67%)\n",
                        "\n",
                        "Filtered label distribution:\n",
                        "fake_label\n",
                        "0    528623\n",
                        "1    100806\n",
                        "Name: count, dtype: int64\n"
                    ]
                }
            ],
            "source": [
                "print(\"Filtering to high confidence samples...\")\n",
                "\n",
                "df_filtered = df[df['label_confidence'].isin(['high_real', 'high_fake'])].copy()\n",
                "\n",
                "print(f\"Filtered dataset size: {len(df_filtered)}\")\n",
                "print(f\"Removed: {len(df) - len(df_filtered)} samples ({(len(df) - len(df_filtered))/len(df)*100:.2f}%)\")\n",
                "print(f\"\\nFiltered label distribution:\")\n",
                "print(df_filtered['fake_label'].value_counts())"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "17fdb37b",
            "metadata": {},
            "source": [
                "## 3. Shared Preprocessing Pipeline"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "5a03f0f8",
            "metadata": {},
            "source": [
                "### 3.1 Select Features"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "id": "901aec76",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Text features: 629429 samples\n",
                        "Numeric features: (629429, 2)\n",
                        "Target distribution:\n",
                        "fake_label\n",
                        "0    528623\n",
                        "1    100806\n",
                        "Name: count, dtype: int64\n"
                    ]
                }
            ],
            "source": [
                "# Text Feature\n",
                "X_text = df_filtered[\"review_text\"].astype(str)\n",
                "\n",
                "# Numerical Features\n",
                "X_numeric = df_filtered[[\"review_length\", \"rating_deviation\"]]\n",
                "\n",
                "# Target\n",
                "y = df_filtered[\"fake_label\"]\n",
                "\n",
                "print(f\"Text features: {len(X_text)} samples\")\n",
                "print(f\"Numeric features: {X_numeric.shape}\")\n",
                "print(f\"Target distribution:\\n{y.value_counts()}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "9f25919d",
            "metadata": {},
            "source": [
                "### 3.2 Train-Test Split"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "id": "a636becb",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Training samples: 503543\n",
                        "Test samples: 125886\n"
                    ]
                }
            ],
            "source": [
                "X_text_train, X_text_test, X_num_train, X_num_test, y_train, y_test = train_test_split(\n",
                "    X_text, X_numeric, y,\n",
                "    test_size=0.2,\n",
                "    random_state=42,\n",
                "    stratify=y\n",
                ")\n",
                "\n",
                "print(f\"Training samples: {len(y_train)}\")\n",
                "print(f\"Test samples: {len(y_test)}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "06dec3dc",
            "metadata": {},
            "source": [
                "### 3.3 TF-IDF Vectorization"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "id": "359ae745",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "TF-IDF train shape: (503543, 5000)\n",
                        "TF-IDF test shape: (125886, 5000)\n"
                    ]
                }
            ],
            "source": [
                "tfidf = TfidfVectorizer(\n",
                "    stop_words=\"english\",\n",
                "    max_features=5000,\n",
                "    ngram_range=(1, 2)\n",
                ")\n",
                "\n",
                "X_tfidf_train = tfidf.fit_transform(X_text_train)\n",
                "X_tfidf_test = tfidf.transform(X_text_test)\n",
                "\n",
                "print(f\"TF-IDF train shape: {X_tfidf_train.shape}\")\n",
                "print(f\"TF-IDF test shape: {X_tfidf_test.shape}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "d375607c",
            "metadata": {},
            "source": [
                "### 3.4 Scale Numeric Features"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 9,
            "id": "cae79275",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Numeric features scaled\n"
                    ]
                }
            ],
            "source": [
                "scaler = StandardScaler()\n",
                "X_num_train_scaled = scaler.fit_transform(X_num_train)\n",
                "X_num_test_scaled = scaler.transform(X_num_test)\n",
                "\n",
                "print(\"Numeric features scaled\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "5bd4bf69",
            "metadata": {},
            "source": [
                "### 3.5 Combine Features"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 10,
            "id": "0f1d3d54",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Combined train shape: (503543, 5002)\n",
                        "Combined test shape: (125886, 5002)\n",
                        "Preprocessing complete - ready to train models!\n"
                    ]
                }
            ],
            "source": [
                "X_train = hstack([X_tfidf_train, X_num_train_scaled])\n",
                "X_test = hstack([X_tfidf_test, X_num_test_scaled])\n",
                "\n",
                "print(f\"Combined train shape: {X_train.shape}\")\n",
                "print(f\"Combined test shape: {X_test.shape}\")\n",
                "print(\"Preprocessing complete - ready to train models!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "6dcb607b",
            "metadata": {},
            "source": [
                "## 4. Model 1: Logistic Regression (Baseline)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 11,
            "id": "7040a2cf",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Training Logistic Regression...\n",
                        "\n",
                        " Logistic Regression Results:\n",
                        "   Accuracy:  0.9222\n",
                        "   Precision: 0.6906\n",
                        "   Recall:    0.9315\n",
                        "   F1-Score:  0.7931\n"
                    ]
                }
            ],
            "source": [
                "print(\"Training Logistic Regression...\")\n",
                "\n",
                "lr_model = LogisticRegression(\n",
                "    max_iter=2000,\n",
                "    class_weight=\"balanced\",\n",
                "    random_state=42\n",
                ")\n",
                "\n",
                "lr_model.fit(X_train, y_train)\n",
                "lr_pred = lr_model.predict(X_test)\n",
                "\n",
                "# Calculate metrics\n",
                "lr_accuracy = accuracy_score(y_test, lr_pred)\n",
                "lr_precision = precision_score(y_test, lr_pred)\n",
                "lr_recall = recall_score(y_test, lr_pred)\n",
                "lr_f1 = f1_score(y_test, lr_pred)\n",
                "\n",
                "print(\"\\n Logistic Regression Results:\")\n",
                "print(f\"   Accuracy:  {lr_accuracy:.4f}\")\n",
                "print(f\"   Precision: {lr_precision:.4f}\")\n",
                "print(f\"   Recall:    {lr_recall:.4f}\")\n",
                "print(f\"   F1-Score:  {lr_f1:.4f}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "8a4dd2d8",
            "metadata": {},
            "source": [
                "## 5. Model 2: Linear SVM (Text Specialist)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 12,
            "id": "dbecedb7",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Training Linear SVM...\n",
                        "\n",
                        "Linear SVM Results:\n",
                        "   Accuracy:  0.9240\n",
                        "   Precision: 0.6953\n",
                        "   Recall:    0.9357\n",
                        "   F1-Score:  0.7978\n"
                    ]
                }
            ],
            "source": [
                "print(\"Training Linear SVM...\")\n",
                "\n",
                "svm_model = LinearSVC(\n",
                "    class_weight=\"balanced\",\n",
                "    random_state=42,\n",
                "    max_iter=2000,\n",
                "    dual=False\n",
                ")\n",
                "\n",
                "svm_model.fit(X_train, y_train)\n",
                "svm_pred = svm_model.predict(X_test)\n",
                "\n",
                "# Calculate metrics\n",
                "svm_accuracy = accuracy_score(y_test, svm_pred)\n",
                "svm_precision = precision_score(y_test, svm_pred)\n",
                "svm_recall = recall_score(y_test, svm_pred)\n",
                "svm_f1 = f1_score(y_test, svm_pred)\n",
                "\n",
                "print(\"\\nLinear SVM Results:\")\n",
                "print(f\"   Accuracy:  {svm_accuracy:.4f}\")\n",
                "print(f\"   Precision: {svm_precision:.4f}\")\n",
                "print(f\"   Recall:    {svm_recall:.4f}\")\n",
                "print(f\"   F1-Score:  {svm_f1:.4f}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "bc24b8e9",
            "metadata": {},
            "source": [
                "## 6. Model 3: Decision Tree (Simple Non-Linear)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 13,
            "id": "c8856640",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Training Decision Tree...\n",
                        "\n",
                        "Decision Tree Results:\n",
                        "   Accuracy:  0.9344\n",
                        "   Precision: 0.7241\n",
                        "   Recall:    0.9537\n",
                        "   F1-Score:  0.8232\n",
                        "   Training Time: 67.96 seconds\n"
                    ]
                }
            ],
            "source": [
                "print(\"Training Decision Tree...\")\n",
                "\n",
                "from sklearn.tree import DecisionTreeClassifier\n",
                "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
                "import time\n",
                "\n",
                "start_time = time.time()\n",
                "\n",
                "dt_model = DecisionTreeClassifier(\n",
                "    max_depth=10,\n",
                "    min_samples_split=20,\n",
                "    min_samples_leaf=10,\n",
                "    class_weight=\"balanced\",\n",
                "    random_state=42\n",
                ")\n",
                "\n",
                "# ✅ DO NOT convert to dense   \n",
                "dt_model.fit(X_train, y_train)\n",
                "\n",
                "dt_pred = dt_model.predict(X_test)\n",
                "\n",
                "# Calculate metrics\n",
                "dt_accuracy = accuracy_score(y_test, dt_pred)\n",
                "dt_precision = precision_score(y_test, dt_pred, zero_division=0)\n",
                "dt_recall = recall_score(y_test, dt_pred, zero_division=0)\n",
                "dt_f1 = f1_score(y_test, dt_pred, zero_division=0)\n",
                "\n",
                "end_time = time.time()\n",
                "\n",
                "print(\"\\nDecision Tree Results:\")\n",
                "print(f\"   Accuracy:  {dt_accuracy:.4f}\")\n",
                "print(f\"   Precision: {dt_precision:.4f}\")\n",
                "print(f\"   Recall:    {dt_recall:.4f}\")\n",
                "print(f\"   F1-Score:  {dt_f1:.4f}\")\n",
                "print(f\"   Training Time: {end_time - start_time:.2f} seconds\")\n"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "c06fdbf8",
            "metadata": {},
            "source": [
                "## 7. Model 4: Random Forest (Ensemble Power)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 14,
            "id": "c9f2a093",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Training Random Forest...\n",
                        "\n",
                        "Random Forest Results:\n",
                        "   Accuracy:  0.9185\n",
                        "   Precision: 0.6893\n",
                        "   Recall:    0.8945\n",
                        "   F1-Score:  0.7786\n",
                        "   Training Time: 11.39 seconds\n"
                    ]
                }
            ],
            "source": [
                "print(\"Training Random Forest...\")\n",
                "\n",
                "# ===== IMPORTS (safe after kernel restart) =====\n",
                "import time\n",
                "from sklearn.ensemble import RandomForestClassifier\n",
                "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
                "\n",
                "start_time = time.time()\n",
                "\n",
                "rf_model = RandomForestClassifier(\n",
                "    n_estimators=100,\n",
                "    max_depth=10,\n",
                "    min_samples_split=20,\n",
                "    min_samples_leaf=10,\n",
                "    class_weight=\"balanced\",\n",
                "    random_state=42,\n",
                "    n_jobs=-1   # uses all CPU cores\n",
                ")\n",
                "\n",
                "# ✅ DO NOT convert to dense\n",
                "rf_model.fit(X_train, y_train)\n",
                "\n",
                "rf_pred = rf_model.predict(X_test)\n",
                "\n",
                "# ===== METRICS =====\n",
                "rf_accuracy = accuracy_score(y_test, rf_pred)\n",
                "rf_precision = precision_score(y_test, rf_pred, zero_division=0)\n",
                "rf_recall = recall_score(y_test, rf_pred, zero_division=0)\n",
                "rf_f1 = f1_score(y_test, rf_pred, zero_division=0)\n",
                "\n",
                "end_time = time.time()\n",
                "\n",
                "print(\"\\nRandom Forest Results:\")\n",
                "print(f\"   Accuracy:  {rf_accuracy:.4f}\")\n",
                "print(f\"   Precision: {rf_precision:.4f}\")\n",
                "print(f\"   Recall:    {rf_recall:.4f}\")\n",
                "print(f\"   F1-Score:  {rf_f1:.4f}\")\n",
                "print(f\"   Training Time: {end_time - start_time:.2f} seconds\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 6. Model 3: XGBoost (Non-Linear Power)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 15,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Training XGBoost...\n",
                        "\n",
                        " XGBoost Results:\n",
                        "   Accuracy:  0.9567\n",
                        "   Precision: 0.8079\n",
                        "   Recall:    0.9572\n",
                        "   F1-Score:  0.8762\n"
                    ]
                }
            ],
            "source": [
                "if XGBOOST_AVAILABLE:\n",
                "    print(\"Training XGBoost...\")\n",
                "    \n",
                "    # Calculate scale_pos_weight\n",
                "    scale_pos_weight = len(y_train[y_train==0]) / len(y_train[y_train==1])\n",
                "    \n",
                "    xgb_model = XGBClassifier(\n",
                "        n_estimators=200,\n",
                "        max_depth=6,\n",
                "        learning_rate=0.1,\n",
                "        scale_pos_weight=scale_pos_weight,\n",
                "        eval_metric=\"logloss\",\n",
                "        random_state=42,\n",
                "        tree_method='hist',\n",
                "        verbosity=0\n",
                "    )\n",
                "    \n",
                "    xgb_model.fit(X_train, y_train)\n",
                "    xgb_pred = xgb_model.predict(X_test)\n",
                "    \n",
                "    # Calculate metrics\n",
                "    xgb_accuracy = accuracy_score(y_test, xgb_pred)\n",
                "    xgb_precision = precision_score(y_test, xgb_pred)\n",
                "    xgb_recall = recall_score(y_test, xgb_pred)\n",
                "    xgb_f1 = f1_score(y_test, xgb_pred)\n",
                "    \n",
                "    print(\"\\n XGBoost Results:\")\n",
                "    print(f\"   Accuracy:  {xgb_accuracy:.4f}\")\n",
                "    print(f\"   Precision: {xgb_precision:.4f}\")\n",
                "    print(f\"   Recall:    {xgb_recall:.4f}\")\n",
                "    print(f\"   F1-Score:  {xgb_f1:.4f}\")\n",
                "else:\n",
                "    print(\" XGBoost not available. Install with: pip install xgboost\")\n",
                "    xgb_accuracy = xgb_precision = xgb_recall = xgb_f1 = None"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 7. Model Comparison\n",
                "\n",
                "Side-by-side comparison of all three models."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 16,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "MODEL COMPARISON SUMMARY\n",
                        "\n",
                        "               Model  Accuracy  Precision   Recall  F1-Score\n",
                        "Logistic Regression  0.922184   0.690568 0.931501  0.793141\n",
                        "         Linear SVM  0.924034   0.695304 0.935717  0.797792\n",
                        "      Decision Tree  0.934385   0.724082 0.953723  0.823187\n",
                        "      Random Forest  0.918545   0.689332 0.894549  0.778646\n",
                        "            XGBoost  0.956699   0.807921 0.957195  0.876246\n",
                        "\n",
                        "BEST MODELS PER METRIC\n",
                        "Accuracy     → XGBoost              (0.9567)\n",
                        "Precision    → XGBoost              (0.8079)\n",
                        "Recall       → XGBoost              (0.9572)\n",
                        "F1-Score     → XGBoost              (0.8762)\n"
                    ]
                }
            ],
            "source": [
                "print(\"MODEL COMPARISON SUMMARY\")\n",
                "\n",
                "import pandas as pd\n",
                "\n",
                "# Base models (always included)\n",
                "comparison_data = {\n",
                "    'Model': [\n",
                "        'Logistic Regression',\n",
                "        'Linear SVM',\n",
                "        'Decision Tree',\n",
                "        'Random Forest'\n",
                "    ],\n",
                "    'Accuracy': [\n",
                "        lr_accuracy,\n",
                "        svm_accuracy,\n",
                "        dt_accuracy,\n",
                "        rf_accuracy\n",
                "    ],\n",
                "    'Precision': [\n",
                "        lr_precision,\n",
                "        svm_precision,\n",
                "        dt_precision,\n",
                "        rf_precision\n",
                "    ],\n",
                "    'Recall': [\n",
                "        lr_recall,\n",
                "        svm_recall,\n",
                "        dt_recall,\n",
                "        rf_recall\n",
                "    ],\n",
                "    'F1-Score': [\n",
                "        lr_f1,\n",
                "        svm_f1,\n",
                "        dt_f1,\n",
                "        rf_f1\n",
                "    ]\n",
                "}\n",
                "\n",
                "# Add XGBoost if available\n",
                "if 'XGBOOST_AVAILABLE' in globals() and XGBOOST_AVAILABLE and xgb_f1 is not None:\n",
                "    comparison_data['Model'].append('XGBoost')\n",
                "    comparison_data['Accuracy'].append(xgb_accuracy)\n",
                "    comparison_data['Precision'].append(xgb_precision)\n",
                "    comparison_data['Recall'].append(xgb_recall)\n",
                "    comparison_data['F1-Score'].append(xgb_f1)\n",
                "\n",
                "comparison_df = pd.DataFrame(comparison_data)\n",
                "\n",
                "print(\"\\n\", comparison_df.to_string(index=False))\n",
                "\n",
                "# ===== BEST MODEL PER METRIC =====\n",
                "print(\"\\nBEST MODELS PER METRIC\")\n",
                "for metric in ['Accuracy', 'Precision', 'Recall', 'F1-Score']:\n",
                "    best_idx = comparison_df[metric].idxmax()\n",
                "    best_model = comparison_df.loc[best_idx, 'Model']\n",
                "    best_value = comparison_df.loc[best_idx, metric]\n",
                "    print(f\"{metric:12} → {best_model:20} ({best_value:.4f})\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 7.2 Confusion Matrices"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 18,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "CONFUSION MATRICES\n",
                        "\n",
                        "Logistic Regression:\n",
                        "[[97310  8415]\n",
                        " [ 1381 18780]]\n",
                        "[[TN  FP]\n",
                        " [FN  TP]]\n",
                        "TN = 97310, FP = 8415, FN = 1381, TP = 18780\n",
                        "\n",
                        "Linear SVM:\n",
                        "[[97458  8267]\n",
                        " [ 1296 18865]]\n",
                        "[[TN  FP]\n",
                        " [FN  TP]]\n",
                        "TN = 97458, FP = 8267, FN = 1296, TP = 18865\n",
                        "\n",
                        "Decision Tree:\n",
                        "[[98398  7327]\n",
                        " [  933 19228]]\n",
                        "[[TN  FP]\n",
                        " [FN  TP]]\n",
                        "TN = 98398, FP = 7327, FN = 933, TP = 19228\n",
                        "\n",
                        "Random Forest:\n",
                        "[[97597  8128]\n",
                        " [ 2126 18035]]\n",
                        "[[TN  FP]\n",
                        " [FN  TP]]\n",
                        "TN = 97597, FP = 8128, FN = 2126, TP = 18035\n",
                        "\n",
                        "XGBoost:\n",
                        "[[101137   4588]\n",
                        " [   863  19298]]\n",
                        "[[TN  FP]\n",
                        " [FN  TP]]\n",
                        "TN = 101137, FP = 4588, FN = 863, TP = 19298\n"
                    ]
                }
            ],
            "source": [
                "print(\"CONFUSION MATRICES\")\n",
                "\n",
                "from sklearn.metrics import confusion_matrix\n",
                "\n",
                "def print_confusion_matrix(model_name, y_true, y_pred):\n",
                "    cm = confusion_matrix(y_true, y_pred)\n",
                "    tn, fp, fn, tp = cm.ravel()\n",
                "    \n",
                "    print(f\"\\n{model_name}:\")\n",
                "    print(cm)\n",
                "    print(\"[[TN  FP]\\n [FN  TP]]\")\n",
                "    print(f\"TN = {tn}, FP = {fp}, FN = {fn}, TP = {tp}\")\n",
                "\n",
                "\n",
                "# ===== Logistic Regression =====\n",
                "print_confusion_matrix(\"Logistic Regression\", y_test, lr_pred)\n",
                "\n",
                "# ===== Linear SVM =====\n",
                "print_confusion_matrix(\"Linear SVM\", y_test, svm_pred)\n",
                "\n",
                "# ===== Decision Tree =====\n",
                "print_confusion_matrix(\"Decision Tree\", y_test, dt_pred)\n",
                "\n",
                "# ===== Random Forest =====\n",
                "print_confusion_matrix(\"Random Forest\", y_test, rf_pred)\n",
                "\n",
                "# ===== XGBoost =====\n",
                "print_confusion_matrix(\"XGBoost\", y_test, xgb_pred)"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "venv",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.11"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}
